# ğŸš€ Fraud Detection API

A FastAPI-based machine learning API for predicting credit card fraud using logistic regression.

## âœ¨ Features

* ğŸ¯ RESTful API for fraud prediction on credit card transactions
* ğŸ¤– Pre-trained logistic regression model for binary classification
* ğŸ“Š Automatic feature extraction from transaction data


## General Application Diagram

![image info](docs/Diagram.png)

## ğŸ³ Docker Setup

### ğŸ“‹ Prerequisites

* Docker
* Docker Compose

### ğŸš€ Quick Start

1. **Build and run with Docker Compose:**

   ```bash
   docker-compose up --build
   ```

   The API will be available at `http://localhost:8080`

2. **Access the API documentation:**

   Open your browser and navigate to `http://localhost:8080/docs` to view the interactive Swagger UI.

## ğŸ”Œ API Endpoints

* `GET /` - API information
* `GET /api/health` - Health check
* `POST /api/predict` - Predict fraud for a transaction

## ğŸ“Š Input Data Structure

The prediction endpoint accepts:

* `merchant` - Merchant name
* `category` - Transaction category
* `city`, `state` - Location information
* `job` - Cardholder's job
* `amt` - Transaction amount
* `lat`, `long` - Geographic coordinates
* `city_pop` - City population
* `trans_date_trans_time` - ISO 8601 datetime (e.g., "2025-12-04T14:30:00")

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ api.py               # FastAPI application
â”œâ”€â”€ basemodel.py         # Pydantic models
â”œâ”€â”€ exploration.ipynb    # Exploratory analysis notebook
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ fraud_model.pkl  # Pre-trained model
â””â”€â”€ data/
    â””â”€â”€ fraud_data.csv   # Training dataset
```

## ğŸ”„ Notebook Reproducibility

To run the exploration notebook and reproduce the analysis:

1. **Create a virtual environment:**

   ```bash
   python -m venv venv
   ```

   On Windows (PowerShell):
   ```powershell
   venv\Scripts\Activate.ps1
   ```

   On macOS/Linux:
   ```bash
   source venv/bin/activate
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt jupyter
   ```


4. **Execute the notebook cells** to reproduce the analysis and model training.

The notebook is configured to work with the pre-trained model stored in `artifacts/fraud_model.pkl`. Running the notebook will regenerate the model if needed.
